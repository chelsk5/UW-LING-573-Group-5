{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chelsk5/UW-LING-573-Group-5/blob/main/LING573_Train_T5_Ante_Hoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authors: Nina Koh, Chelsea Kendrick, Vanesa Marar\n",
        "# Install dependencies\n",
        "\n",
        "!pip install -q \\\n",
        "  transformers==4.41.0 \\\n",
        "  datasets==2.19.1 \\\n",
        "  huggingface-hub==0.28.1 \\\n",
        "  peft==0.8.2 \\\n",
        "  evaluate rouge-score nltk\n",
        "\n",
        "!pip install accelerate==0.27.2"
      ],
      "metadata": {
        "id": "7QKo643cp2ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16a9f13-25cb-4451-dc42-b9a1feb7404e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting accelerate==0.27.2\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2025.7.9)\n",
            "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.8.1\n",
            "    Uninstalling accelerate-1.8.1:\n",
            "      Successfully uninstalled accelerate-1.8.1\n",
            "Successfully installed accelerate-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI7U51uL7StI",
        "outputId": "83e6c73e-1fe8-4ce1-8bbe-bb75ae7efaca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UW-LING-573-Group-5'...\n",
            "remote: Enumerating objects: 734, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 734 (delta 124), reused 131 (delta 87), pack-reused 553 (from 1)\u001b[K\n",
            "Receiving objects: 100% (734/734), 601.57 KiB | 4.56 MiB/s, done.\n",
            "Resolving deltas: 100% (224/224), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone repo & set up environment\n",
        "!git clone https://github.com/chelsk5/UW-LING-573-Group-5.git\n",
        "!mv UW-LING-573-Group-5 UW_LING_573_Group_5 # Python modules use underscores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "02E-ajOr9_7_",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c2238f-536f-4e0a-8485-98389d9a81e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "CreateOpinionGraph.py   LING573_Zero_Shot_T5.ipynb  rouge.py\n",
            "gold_info.py            mmr.py                      \u001b[0m\u001b[01;34mt5-small_results\u001b[0m/\n",
            "lex-rank.py             \u001b[01;34mmmr_results\u001b[0m/                tf-idf.py\n",
            "\u001b[01;34mlexrank_results\u001b[0m/        README.md                   \u001b[01;34mtf-idf_results\u001b[0m/\n",
            "LING573_Model.ipynb     requirements.txt\n",
            "LING573_Train_T5.ipynb  rouge_eval.py\n"
          ]
        }
      ],
      "source": [
        "# %cd UW_LING_573_Group_5\n",
        "!git checkout main\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKDzu-BIKI_v"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "53N0paoCC2gb"
      },
      "outputs": [],
      "source": [
        "# 1. Load data from local GitHub folder\n",
        "# import os, re, glob\n",
        "import json\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def clean_line(line):\n",
        "    line = line.lower()\n",
        "    # line = re.sub(r'[^\\w\\s]', '', line)\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "    return line\n",
        "\n",
        "def load_from_json(json_path):\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    examples = []\n",
        "    for topic, reviews in data.items():\n",
        "        cleaned_reviews = [clean_line(r) for r in reviews]\n",
        "        full_text = \" \".join(cleaned_reviews)\n",
        "        # Dummy gold summary — replace later if needed\n",
        "        gold_summary = cleaned_reviews[0] if cleaned_reviews else \"\"\n",
        "        examples.append({\n",
        "            \"topic\": topic,\n",
        "            \"reviews\": full_text,\n",
        "            \"gold_summary\": gold_summary\n",
        "        })\n",
        "    return examples\n",
        "\n",
        "# def load_local_opinosis(data_dir):\n",
        "#     examples = []\n",
        "#     search_path = os.path.join(data_dir, \"*.txt.data\")\n",
        "#     files = glob.glob(search_path)\n",
        "\n",
        "#     for file in files:\n",
        "#         topic = os.path.splitext(os.path.basename(file))[0].replace(\".txt\", \"\")\n",
        "#         with open(file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "#             lines = [clean_line(line.strip()) for line in f if line.strip()]\n",
        "#             if lines:\n",
        "#                 full_text = \" \".join(lines)\n",
        "#                 gold_summary = lines[0]  # TEMP: use first line as dummy summary\n",
        "#                 examples.append({\n",
        "#                     \"topic\": topic,\n",
        "#                     \"reviews\": full_text,\n",
        "#                     \"gold_summary\": gold_summary\n",
        "#                 })\n",
        "#     return examples\n",
        "\n",
        "# Load data and split\n",
        "# data_dir = \"/content/UW_LING_573_Group_5/data\"\n",
        "# all_examples = load_local_opinosis(data_dir)\n",
        "\n",
        "# train_examples, test_examples = train_test_split(all_examples, test_size=0.2, random_state=1)\n",
        "# train_data = Dataset.from_list(train_examples)\n",
        "# test_data = Dataset.from_list(test_examples)\n",
        "\n",
        "# Load selected reviews from specified JSON file\n",
        "# json_path = \"/content/UW_LING_573_Group_5/tf-idf_results/tfidf_ante-hoc.json\"\n",
        "# json_path = \"/content/UW_LING_573_Group_5/lexrank_results/lexrank_ante-hoc.json\"\n",
        "json_path = \"/content/UW_LING_573_Group_5/mmr_results/mmr_ante-hoc.json\"\n",
        "\n",
        "examples = load_from_json(json_path)\n",
        "\n",
        "# Split into train/test and convert to HuggingFace Dataset\n",
        "train_examples, test_examples = train_test_split(examples, test_size=0.2, random_state=1)\n",
        "train_data = Dataset.from_list(train_examples)\n",
        "test_data = Dataset.from_list(test_examples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing\n",
        "def clean_data(example):\n",
        "    \"\"\"Preserves topic_id, reviews, and gold_summary.\"\"\"\n",
        "    return {\n",
        "        \"topic_id\": example[\"topic\"], # Keep the 'topic' key and rename it to 'topic_id' for clarity\n",
        "        \"reviews\": example[\"reviews\"],\n",
        "        # We will overwrite gold_summary with the real one later\n",
        "        \"gold_summary\": example[\"gold_summary\"] # Keep the dummy summary for now if needed elsewhere, or remove if not\n",
        "    }\n",
        "\n",
        "# Apply mapping\n",
        "cleaned_train = train_data.map(clean_data)\n",
        "cleaned_test = test_data.map(clean_data)\n",
        "\n",
        "# Print a couple of examples to check for 'topic_id'\n",
        "print(\"Input reviews:\")\n",
        "print(cleaned_train[0][\"reviews\"])\n",
        "print(\"\\nTarget summary (dummy):\") # Note this is the dummy summary\n",
        "print(cleaned_train[0][\"gold_summary\"])\n",
        "print(\"\\nTopic ID:\") # Check that topic_id is now present\n",
        "print(cleaned_train[0][\"topic_id\"])\n",
        "\n",
        "\n",
        "print(\"\\nInput reviews:\")\n",
        "print(cleaned_train[1][\"reviews\"])\n",
        "print(\"\\nTarget summary (dummy):\") # Note this is the dummy summary\n",
        "print(cleaned_train[1][\"gold_summary\"])\n",
        "print(\"\\nTopic ID:\") # Check that topic_id is now present\n",
        "print(cleaned_train[1][\"topic_id\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "4382252d4b86473fa434557ac79152e4",
            "2a55a35dc1ae45dda7a48713e579fd0a",
            "06a517ed5cf8471b91206ad915cae3b4",
            "dc2c63705ae64c6dbbd95e266d6fffb1",
            "30536fbca40544edb92ff09980a6cae8",
            "7f65879f54604ffabc1b566a75af93ff",
            "bb3e73b52e844fdea156182a867f0585",
            "62f469989acf4285bc2c52aebe1f43df",
            "fb238e86dad245e99a3d2aaec987d868",
            "1b20f95858f747f591cca4d7e9088529",
            "c35d16e207fa47fa8aed403fc1775c3b",
            "ad73835a3c574b7baa2be1fe3db51efb",
            "3b59224287cf40398fc961ee851e7a4f",
            "ea28fafcc33949af8cde653c949f9156",
            "aba5653075f04a64ace5e5d2998bdb9e",
            "830e4106352441b3a7b2f4664f5fcc19",
            "31ed57c913b24a998547eb2cc83a33da",
            "c2433964979143f785284bb0334498c0",
            "f74d0436839a41f8bca2a621aa80e918",
            "66bd9e9926ec482fa3c769471e5b064d",
            "6aff45901ce24430978e420433c6a83e",
            "d86aa25d53c845ceb45fa45cf4f85202"
          ]
        },
        "id": "oHa47oSpPKRS",
        "outputId": "917ece00-191c-4b2a-ee36-2547261284ec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4382252d4b86473fa434557ac79152e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad73835a3c574b7baa2be1fe3db51efb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input reviews:\n",
            "front seats much more comfortable . ride is very good, but seats are just a little firm . front seats are very uncomfortable . i love the seats, they are supportive . leather seats are very comfortable . this accord has more road noise than i like and the seats tend to be hard, unlike my other accords . at first the seats seemed stiffer than i'd like, but after making a 2 1 2 hour trip, it felt very comfortable once i got the seat and lumbar adjusted to my liking .\n",
            "\n",
            "Target summary (dummy):\n",
            "front seats much more comfortable .\n",
            "\n",
            "Topic ID:\n",
            "seats_honda_accord_2008\n",
            "\n",
            "Input reviews:\n",
            "the car is great, both with styling and performance . engine performance is very lacking . good looking inside and out, comfortable and roomy, commendable performance, and excellent gas mileage . very happy with the car enjoy the ride and performance . the car is superb, performance, styling, quality, engineering, fit and finish , the whole banana ! when i first tested the ex, l v6, the performance and handling of the car sold me, i had to get it and i did . still enjoy interior and exterior styling as well as overall performance and handling .\n",
            "\n",
            "Target summary (dummy):\n",
            "the car is great, both with styling and performance .\n",
            "\n",
            "Topic ID:\n",
            "performance_honda_accord_2008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Load tokenizer & model\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
        "\n",
        "# quantization_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_compute_dtype=\"float16\",\n",
        "#     bnb_4bit_quant_type=\"nf4\",  # You can also use \"fp4\" depending on your needs\n",
        "#     bnb_4bit_use_double_quant=True\n",
        "# )\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name, quantization_config=quantization_config, device_map=\"auto\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Hzps4oQKgYG1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Tokenize reviews & gold summaries from Github repo\n",
        "\n",
        "def load_gold_summary_for_review(topic_id, gold_dir=\"summaries-gold\"):\n",
        "    \"\"\"Loads and combines .gold files for a given topic ID from the summaries-gold/ directory.\"\"\"\n",
        "    topic_path = os.path.join(gold_dir, topic_id)\n",
        "    gold_summary = \"\"\n",
        "    if os.path.exists(topic_path):\n",
        "        for fname in os.listdir(topic_path):\n",
        "            if fname.endswith(\".gold\"):\n",
        "                with open(os.path.join(topic_path, fname), \"r\", encoding=\"utf-8\") as f:\n",
        "                    gold_summary += f.read().strip() + \" \"\n",
        "    return gold_summary.strip()\n",
        "\n",
        "def tokenize_data(cleaned_data, tokenizer):\n",
        "    \"\"\"Convert the raw text into token IDs for model processing using extracted gold summary.\"\"\"\n",
        "    topic_id = cleaned_data[\"topic_id\"]\n",
        "    reviews_text = cleaned_data[\"reviews\"]\n",
        "\n",
        "    gold_summary = load_gold_summary_for_review(topic_id)\n",
        "\n",
        "    pref_text = \"summarize: \" + reviews_text\n",
        "\n",
        "    tokenized_input = tokenizer(\n",
        "        pref_text,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    labels = tokenizer([gold_summary], max_length=64, truncation=True)\n",
        "    tokenized_input[\"labels\"] = labels[\"input_ids\"][0]\n",
        "\n",
        "    return tokenized_input\n",
        "\n",
        "# Example usage (assuming your data includes 'topic_id', 'reviews'):\n",
        "tokenized_train = [tokenize_data(d, tokenizer) for d in cleaned_train]\n",
        "tokenized_test = [tokenize_data(d, tokenizer) for d in cleaned_test]\n",
        "\n",
        "# Check tokenization\n",
        "print(\"Tokenized input example (input_ids):\")\n",
        "print(tokenized_train[0][\"input_ids\"])\n",
        "print(\"Tokenized target (labels):\")\n",
        "print(tokenized_train[0][\"labels\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g7E4loULSwI",
        "outputId": "8d689a80-4c38-4f67-d4fa-a272edacf685"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized input example (input_ids):\n",
            "[21603, 10, 851, 6116, 231, 72, 1965, 3, 5, 2564, 19, 182, 207, 6, 68, 6116, 33, 131, 3, 9, 385, 1669, 3, 5, 851, 6116, 33, 182, 14209, 3, 5, 3, 23, 333, 8, 6116, 6, 79, 33, 12758, 3, 5, 4295, 6116, 33, 182, 1965, 3, 5, 48, 4408, 65, 72, 1373, 4661, 145, 3, 23, 114, 11, 8, 6116, 2134, 12, 36, 614, 6, 9770, 82, 119, 4408, 7, 3, 5, 44, 166, 8, 6116, 3776, 14537, 49, 145, 3, 23, 31, 26, 114, 6, 68, 227, 492, 3, 9, 204, 209, 204, 1781, 1469, 6, 34, 1800, 182, 1965, 728, 3, 23, 530, 8, 3143, 11, 3, 5171, 1047, 13108, 12, 82, 23340, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenized target (labels):\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create batch of examples\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# Dynamically pad sentences to the longest length\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ],
      "metadata": {
        "id": "NkSfR_pxLUWi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Train model\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "\n",
        "# Manually tune hyperparameters\n",
        "\n",
        "# Define training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./t5-small-results\", # folder to save progress\n",
        "    evaluation_strategy=\"epoch\", # evaluate after one complete pass\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8, # small batch size for small data\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3, # number of checkpoints (subject to change?)\n",
        "    num_train_epochs=5, # total passes thru data (also stc...)\n",
        "    generation_max_length=100,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,# changed to False to avoid ValueError\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator)\n",
        "\n",
        "# Train (finally)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "lsiz5KlGtfqz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "598e3403-5563-458f-de83-327f3998ecee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 07:02, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.833783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.075768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.591122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.313440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.205025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=25, training_loss=7.044909057617187, metrics={'train_runtime': 443.0107, 'train_samples_per_second': 0.451, 'train_steps_per_second': 0.056, 'total_flos': 27068360294400.0, 'train_loss': 7.044909057617187, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. *** COPY Save predictions & labels in json files COPY ***\n",
        "import os, json\n",
        "from datasets import concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Combine tokenized train and test sets\n",
        "tokenized_train_ds = Dataset.from_list(tokenized_train)\n",
        "tokenized_test_ds = Dataset.from_list(tokenized_test)\n",
        "tokenized_opinosis = concatenate_datasets([tokenized_train_ds, tokenized_test_ds])\n",
        "print(tokenized_opinosis.column_names)\n",
        "\n",
        "\n",
        "# Remove raw text fields (adjust names as needed)\n",
        "try:\n",
        "    tokenized_opinosis = tokenized_opinosis.remove_columns(\n",
        "        [\"review_sents\", \"summaries\", \"reviews\", \"gold_summary\"]\n",
        "    )\n",
        "except ValueError as e:\n",
        "    print(f\"Warning: Could not remove columns. Check column names. Error: {e}\")\n",
        "    # You might want to inspect the column names here\n",
        "    print(\"Current columns:\", tokenized_opinosis.column_names)\n",
        "\n",
        "# Create DataLoader with automatic padding\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "dataloader = DataLoader(tokenized_opinosis, batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "# Prepare model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "decoded_preds = []\n",
        "topic_ids = []\n",
        "\n",
        "# Extract topic_ids from the original cleaned datasets before they were converted to lists of dictionaries\n",
        "# or from tokenized_opinosis if topic_id was preserved during tokenization\n",
        "# Assuming topic_id is not directly in tokenized_opinosis after removing columns,\n",
        "# we need to get it from the original cleaned data.\n",
        "# However, the original `cleaned_train` and `cleaned_test` are Datasets, not lists, and the\n",
        "# `clean_data` function didn't add `topic_id` to the dataset structure itself,\n",
        "# but rather returned a dictionary with 'topic_id'. The lists `tokenized_train` and\n",
        "# `tokenized_test` were created from these dictionaries.\n",
        "# Let's assume the original `all_examples` before the split contains the topic_ids.\n",
        "# We can map back to the original examples or assume the order is preserved.\n",
        "# A safer approach is to re-load or re-process to get topic_ids alongside the tokenized data.\n",
        "# Given the current notebook state, the easiest way is to get topic_ids from the original all_examples\n",
        "# and assume the order in the combined tokenized dataset matches the order of combining the original lists.\n",
        "\n",
        "# Re-loading or assuming order might not be robust. Let's re-create a structure that keeps topic_id.\n",
        "# Instead of removing columns early, let's keep topic_id in the tokenized dataset.\n",
        "# I'll modify the tokenize_data function to keep topic_id if it exists in the input.\n",
        "# (This would require modifying the tokenize_data function in cell 5g7E4loULSwI, which I cannot do directly here)\n",
        "\n",
        "# A workaround for the current state: Since tokenized_train and tokenized_test were created from\n",
        "# lists of dictionaries which included 'topic_id', we can iterate through the original\n",
        "# train_examples and test_examples lists to get topic_ids in the correct order.\n",
        "\n",
        "combined_examples = train_examples + test_examples\n",
        "for example in combined_examples:\n",
        "    if \"topic\" in example: # Check for the original 'topic' key\n",
        "         topic_ids.append(example[\"topic\"])\n",
        "\n",
        "\n",
        "# Generate summaries\n",
        "for batch in dataloader:\n",
        "    # Ensure batch is moved to the correct device\n",
        "    batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=100,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    decoded_batch = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "    decoded_preds.extend([d.strip() for d in decoded_batch])\n",
        "\n",
        "# Zip topic_ids and decoded_preds together\n",
        "topic_summary_dict = {}\n",
        "# Ensure topic_ids and decoded_preds have the same length\n",
        "if len(topic_ids) == len(decoded_preds):\n",
        "    for topic, pred in zip(topic_ids, decoded_preds):\n",
        "        topic_summary_dict[topic] = [pred]\n",
        "else:\n",
        "    print(f\"Warning: Mismatch between number of topic_ids ({len(topic_ids)}) and generated summaries ({len(decoded_preds)}).\")\n",
        "    # Handle the mismatch, e.g., by only zipping the minimum length\n",
        "    min_len = min(len(topic_ids), len(decoded_preds))\n",
        "    for topic, pred in zip(topic_ids[:min_len], decoded_preds[:min_len]):\n",
        "         topic_summary_dict[topic] = [pred]\n",
        "\n",
        "\n",
        "# Save generated summaries\n",
        "with open(\"mmr_antehoc_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(topic_summary_dict, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Decode reference summaries from trainer (just for labels)\n",
        "predictions = trainer.predict(tokenized_opinosis)\n",
        "labels = np.where(predictions.label_ids != -100, predictions.label_ids, tokenizer.pad_token_id)\n",
        "decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "decoded_labels = [label.strip() for label in decoded_labels]\n",
        "\n",
        "# Save reference summaries\n",
        "with open(\"reference_summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(decoded_labels, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# import os, json\n",
        "# from collections import defaultdict\n",
        "# from datasets import concatenate_datasets\n",
        "\n",
        "# # Model-generated summaries\n",
        "# tokenized_opinosis = concatenate_datasets([tokenized_train, tokenized_test]) # full dataset\n",
        "# predictions = trainer.predict(tokenized_opinosis, max_length=100) # use full dataset, not just training\n",
        "# pred_ids = np.argmax(predictions.predictions, axis=-1)\n",
        "# decoded_preds = tokenizer.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
        "\n",
        "# with open(\"t5_summaries.json\", \"w\") as f:\n",
        "#     json.dump(decoded_preds, f, indent=2)\n",
        "\n",
        "# # Reference summaries\n",
        "# labels = np.where(predictions.label_ids != -100, predictions.label_ids, tokenizer.pad_token_id)\n",
        "# decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "# with open(\"reference_summaries.json\", \"w\") as f:\n",
        "#     json.dump(decoded_labels, f, indent=2)\n",
        "\n",
        "# system_dir = \"t5-small-results/system_summaries\" # t5 predictions\n",
        "# model_dir = \"t5-small-results/model_summaries\" # gold reference\n",
        "# os.makedirs(system_dir, exist_ok=True)\n",
        "# os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Write to output files, where each file contains a single summary\n",
        "# for i, (pred, ref) in enumerate(zip(decoded_preds, decoded_labels)):\n",
        "#     with open(f\"{system_dir}/{i}.txt\", \"w\") as sys_f:\n",
        "#         sys_f.write(pred.strip() + \"\\n\")\n",
        "#     with open(f\"{model_dir}/{i}.A.1.txt\", \"w\") as ref_f:\n",
        "#         ref_f.write(ref.strip() + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e8de1301-afb3-4b39-b62a-7761bbfddd2e",
        "id": "83rgX8Xy7vOF"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['input_ids', 'attention_mask', 'labels']\n",
            "Warning: Could not remove columns. Check column names. Error: Column name ['gold_summary', 'reviews', 'summaries', 'review_sents'] not in the dataset. Current columns in the dataset: ['input_ids', 'attention_mask', 'labels']\n",
            "Current columns: ['input_ids', 'attention_mask', 'labels']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4382252d4b86473fa434557ac79152e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a55a35dc1ae45dda7a48713e579fd0a",
              "IPY_MODEL_06a517ed5cf8471b91206ad915cae3b4",
              "IPY_MODEL_dc2c63705ae64c6dbbd95e266d6fffb1"
            ],
            "layout": "IPY_MODEL_30536fbca40544edb92ff09980a6cae8"
          }
        },
        "2a55a35dc1ae45dda7a48713e579fd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f65879f54604ffabc1b566a75af93ff",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3e73b52e844fdea156182a867f0585",
            "value": "Map: 100%"
          }
        },
        "06a517ed5cf8471b91206ad915cae3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62f469989acf4285bc2c52aebe1f43df",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb238e86dad245e99a3d2aaec987d868",
            "value": 40
          }
        },
        "dc2c63705ae64c6dbbd95e266d6fffb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b20f95858f747f591cca4d7e9088529",
            "placeholder": "​",
            "style": "IPY_MODEL_c35d16e207fa47fa8aed403fc1775c3b",
            "value": " 40/40 [00:00&lt;00:00, 764.82 examples/s]"
          }
        },
        "30536fbca40544edb92ff09980a6cae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f65879f54604ffabc1b566a75af93ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3e73b52e844fdea156182a867f0585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62f469989acf4285bc2c52aebe1f43df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb238e86dad245e99a3d2aaec987d868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b20f95858f747f591cca4d7e9088529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35d16e207fa47fa8aed403fc1775c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad73835a3c574b7baa2be1fe3db51efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b59224287cf40398fc961ee851e7a4f",
              "IPY_MODEL_ea28fafcc33949af8cde653c949f9156",
              "IPY_MODEL_aba5653075f04a64ace5e5d2998bdb9e"
            ],
            "layout": "IPY_MODEL_830e4106352441b3a7b2f4664f5fcc19"
          }
        },
        "3b59224287cf40398fc961ee851e7a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ed57c913b24a998547eb2cc83a33da",
            "placeholder": "​",
            "style": "IPY_MODEL_c2433964979143f785284bb0334498c0",
            "value": "Map: 100%"
          }
        },
        "ea28fafcc33949af8cde653c949f9156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74d0436839a41f8bca2a621aa80e918",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66bd9e9926ec482fa3c769471e5b064d",
            "value": 11
          }
        },
        "aba5653075f04a64ace5e5d2998bdb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aff45901ce24430978e420433c6a83e",
            "placeholder": "​",
            "style": "IPY_MODEL_d86aa25d53c845ceb45fa45cf4f85202",
            "value": " 11/11 [00:00&lt;00:00, 192.62 examples/s]"
          }
        },
        "830e4106352441b3a7b2f4664f5fcc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ed57c913b24a998547eb2cc83a33da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2433964979143f785284bb0334498c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74d0436839a41f8bca2a621aa80e918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66bd9e9926ec482fa3c769471e5b064d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aff45901ce24430978e420433c6a83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86aa25d53c845ceb45fa45cf4f85202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}