{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI7U51uL7StI",
    "outputId": "b9108e8e-1c5f-4186-9446-f8af9b5aa676"
   },
   "outputs": [],
   "source": [
    "# Authors: Nina Koh, Chelsea Kendrick\n",
    "# Setup: Clone repo & install dependencies\n",
    "\n",
    "!rm -rf UW-LING-573-Group-5\n",
    "!git clone https://github.com/chelsk5/UW-LING-573-Group-5.git\n",
    "\n",
    "!pip install -r UW-LING-573-Group-5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02E-ajOr9_7_",
    "outputId": "e62c8eab-7941-42c3-8305-b6d3d7ae5357"
   },
   "outputs": [],
   "source": [
    "%cd UW-LING-573-Group-5/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKDzu-BIKI_v"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53N0paoCC2gb",
    "outputId": "0b37b5a6-668c-4949-8158-57813094fc42"
   },
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "from datasets import load_dataset\n",
    "opinosis = load_dataset(\"kavgan/opinosis\", split=\"train\") # HuggingFace hub\n",
    "dataset = opinosis.train_test_split(test_size=0.2,seed=1) # follow common split ratio\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uburJXDhoURE",
    "outputId": "e218e6c1-aa38-4685-88bc-0190a5cb0476"
   },
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "def clean_data(sent_to_sum):\n",
    "  \"\"\"Cleans the given review and returns a dictionary\n",
    "  of aggregated reviews and the first gold summary\"\"\"\n",
    "  reviews = sent_to_sum[\"review_sents\"].strip()\n",
    "  # Choose the first gold summary\n",
    "  gold_summary = sent_to_sum[\"summaries\"][0].strip()\n",
    "  return {\n",
    "      \"reviews\": reviews,\n",
    "      \"gold_summary\": gold_summary\n",
    "  }\n",
    "\n",
    "# Sanity check!\n",
    "# Apply cleaning to a small sample\n",
    "data = load_dataset(\"kavgan/opinosis\")[\"train\"]\n",
    "cleaned_data = data.map(clean_data)\n",
    "\n",
    "# Print the result\n",
    "print(\"Input reviews:\")\n",
    "print(cleaned_data[0][\"reviews\"])\n",
    "print(\"\\nTarget summary:\")\n",
    "print(cleaned_data[0][\"gold_summary\"])\n",
    "\n",
    "print(\"\\nInput reviews:\")\n",
    "print(cleaned_data[1][\"reviews\"])\n",
    "print(\"\\nTarget summary:\")\n",
    "print(cleaned_data[1][\"gold_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "715812a720f84dd3872e0cd48aea4cc5",
      "29b436777ffa45efafa4993970b586ae",
      "e1d11118feea4bd2b55c9bd74c554f05",
      "842e353ffaed4eb6b46bb4df0e7491c7",
      "4b862511dc34413ca2ba54d9a5c74e37",
      "3a943b9bc3f3431689001db3106de69b",
      "c80cdcbfaf57441d96e46bb4a09a3c7b",
      "88fb588e57044c66bcbd9ae995dcbdfb",
      "9b1d723452f546f382b00ce728148186",
      "caa083295b29479a9c3969913a90e2db",
      "fc87bae4afdc46c0845c00b6b78eb25b",
      "7a225b4009b04a6e8298e1eeaff24d14",
      "a3fb01b05deb4e79876e3814ed8735ea",
      "738f911ab6844d14b4cc009b85572767",
      "ed4cdafca8854740b51d5af395b8cd2d",
      "e792dec7d21d4888ae97c5eb8b10fb43",
      "ba23988ac1094933ae3cb3927375412a",
      "d5e10d90023f46b297bd358e3a638d95",
      "bb5da66708f14fce9f87d4620e2eddfc",
      "39de9b76b21c408982e062f029445bd0",
      "efc3a65bb60c415a8d07199867970b67",
      "506fa802e96e42e480865a3a10f98373"
     ]
    },
    "id": "Hzps4oQKgYG1",
    "outputId": "0059a448-c972-43b9-a035-f1731ef2fc14"
   },
   "outputs": [],
   "source": [
    "# 3. Load tokenizer & model\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "e09919f7e8c14c7680194a0e46c485de",
      "a9c10d7653a24786a4d234399870029b",
      "c0e3cbc2f6da4743af448af3e8bc1a02",
      "0bee153d66c3417baafeba164603593f",
      "174e44c90dc04b8fbfe2868e6aab3bc4",
      "8dd4fa0716dc4228a65aafefb952a189",
      "0a09b39489bb49048275ab9a8adf5db2",
      "92e9e0a59484465588d6b31c106c6e3c",
      "1648897f906740609455f8dffee9ba35",
      "5c416eef5ed641c793e48ea5a6488587",
      "7036e49e77f340258a92c06f6d583f5d"
     ]
    },
    "id": "bzweEIDlGItS",
    "outputId": "18936a03-755d-47fd-938a-561f2cb25718"
   },
   "outputs": [],
   "source": [
    "# 4. Tokenize reviews & gold summaries\n",
    "def tokenize_data(cleaned_data):\n",
    "  \"\"\"Convert the raw text into token IDs for model processing\"\"\"\n",
    "  # Prepend task for T5 to execute\n",
    "  pref_text = \"summarize: \" + cleaned_data[\"reviews\"]\n",
    "\n",
    "  # Tokenize input (reviews)\n",
    "  # Ensure that text does not exceed (is in fact exactly) maximum of 512 tokens\n",
    "  tokenized_input = tokenizer(pref_text, max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "  # Tokenize target output (gold summary)\n",
    "  gold_summary = cleaned_data[\"gold_summary\"]\n",
    "  labels = tokenizer([gold_summary], max_length=64, truncation=True) # expects a list\n",
    "\n",
    "  # Add target labels to the model input\n",
    "  # Format for HuggingFace Trainer\n",
    "  tokenized_input[\"labels\"] = labels[\"input_ids\"][0] # get first (& only) item of nested list\n",
    "  return tokenized_input\n",
    "\n",
    "#apply tokenization to data\n",
    "tokenized_train = cleaned_data.map(tokenize_data, batched=False) # one row at a time\n",
    "\n",
    "#check tokenization\n",
    "print(\"Tokenized input example (input_ids):\")\n",
    "print(tokenized_train[0][\"input_ids\"])\n",
    "print(\"Tokenized target (labels):\")\n",
    "print(tokenized_train[0][\"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkSfR_pxLUWi"
   },
   "outputs": [],
   "source": [
    "# 5.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
